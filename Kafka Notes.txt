Date:      : OCT-2022
Rvised Date: FEB-2023
------------------------------------------------------------------------------------------------------ 
ISR: In-shink Replica

Replication: Only one leader can be apply on only one Broker.
Producer : It will produce the messages into topic.
Producer waits for the acknowledgement from leader.
by default acks=1(it means it will wait for the acknowledgement.) (limited data loss)
if acks = 0; it won't wait for the acknowledgement. (there is a high chance of lossing the data)
if acks = all (no data loss)

Messages keys : if i want to send key along with messages
When we use message keys and if we send millions of records and all reccords will go to one broker only
(but we can not define first message goes to which broker)it may goes to B0 or B1 or B2
We may this topic when we want to over come the network letency inorder to send messages to topic
Suppose if we configure 3 brokers
B1    B2   B3
T-A   T-A  T-A
P0    P1    p2


In Kafak Producer and Consumer both are 

Conumers and Consumer Groups
---------------------------
Consumer will read the data from topics in order.

Consumer Groups
---------------
We can configure n number of consumers as per our requirement.

Suppose we have three partitions
B1    B2   B3
T-A   T-A  T-A
P0    P1    p2

and when we configure 4 consumers
C1 will read the data from p0 of B1 and
C2 will read the data from P1 of B2 and 
C3 will read the data from P2 of B3 and 
C4 will be inactive state.

C4 will be active when any of the consumer is down.

Consumer Ofset: Consumer also having offset concept that means 
just assume that we have this many partitions and 
when Consumer is read data from topic 1 to 3 and C1 will went offline when C4 will be comes to picture It will start reading the data from 4th partition.
(it won't re read it from starting)
1 2 3 4 5 6 7 8 9 10


Deliver Symatics
=================
At  most once  (data loss ) 
At  least once  (Duplication of data process)
Exact once (This feature works only when we deals with Kafka(Producer) to Kafka(Consumer))




Zookeeper:
==========
Zookeeper managed the kafka brokers
It sends notifications to Kafka client (when broker down and etc)
At least three zookeeper server should be present in production it should be odd number only else it won't work.
like number is 3 , 5 and 7
Zookeeper also having leader election and followers.
If we configured 3 zookeeper and 5 brokers
All 3 zookeeper's are interconected.
All 5 brokers are connected to zookeeper.
We don't need to know which broker is connected to which zookeeper and every information shared with all all the three 3 zookeeper.



Kafka Installation
==================
Step1: Install JDK11 or above version
		Java 11  JDK
		
Step2: Install Kafka from below link https://kafka.apache.org/downloads
		Scala 2.13  - kafka_2.13-2.6.0.tgz (asc, sha512)
        After downloading the kafks binary, unzip it and go to command line and navigate into instalation path:
		I:\Apache Kafka\kafka_2.13-2.6.0> ls
		LICENSE NOTICE BIN CONFIG LIBS SITE-DOCS
		cd bin\windows>ls
		kafka-console-consumer.bat 
		kafka-console-producer.bat
		
		zookeeper-server-start.bat
		
		
		Kafka Topics Snipping not working
		-------------------------------
		Topics is an Entity in Kafka with name.
		Kafka Producer -------> Kafka Broker ----> Poll Topic A ------------> Kafka Consumer [read the message from Topic A]
		                          Topic A  
		                           { ABC }
        Note: Even after producer reads the messages from the Tpic still message resides in topic for specified time.
		
		Tpics and Partitions  Snipping not working
		----------------------
		Partition is where the message lives in Topics
		Each Topic will be created with  one or more partitions.
		
		Each partition is an ordered, immutable and sequence of records.
		Each record is assigned a sequential number called offset.
		Each partition is independent of each other.
		Ordering is guaranteed only at the partition level.
		All the records are persistent in the commit log in the file system where kafka installed.
		
		Topic A [Kafka Producer]
		Partition 0  0 1 2 3 4 etc
		Partition 1  0 1 2 3 4 5 6 etc
		
		
		
		
		
		
Step3: Change the zookeeper log file change.
		for this go to path below I:\Apache Kafka\kafka_2.13-2.6.0\config
		Zookeeper default port number is : 2181
		Zookeeper logs will be store in the path below /tmp/zookeeper (if we want we can chnage the path as per our convient)
		
Step4: In order to create broker first Zookeeper should start.
       we have two properties file 	under config directory
       one is zookeeper.properties and server.properties 
	   Zookeeper.properties is for creating zookeeper
	   server.properties 	is for creating broker
Step5: Start the zookeeper first
       cd bin ./zookeeper-server-start.sh  (bat file is for running on windows cd bin/windows ./zookeeper-server-start.bat)
	   when run the above command you will encounter with problem with below error
	   USAGE ERROR
Step6: in order to run zookeeper server u should follow the below 
		zookeeper-server-start.bat I:\Apache Kafka\kafka_2.13-2.6.0\config\zookeeper.properties
		Note: this time also zookeeper server won't come up, we will get error with 
		Error: Could not find or load main class files\kafka_2.12-2.4.0\libs\activation-1.1.1.jar;
		Solution is: On windows, the kafka path cannot contain spaces. Try I:\Kafka\kafka_2.13-2.6.0\config\zookeeper.properties.
Step7: now zookeeper will run succeessfully without fail with 2181 port number.	
       Also we cna run our zookeeper in backgroud for this use beow command
	   zookeeper-server-start.bat -daemon I:\Apache Kafka\kafka_2.13-2.6.0\config\zookeeper.properties
	   In this case if we want to know the status of the zookeeper whether running or not for issue follow command (this command may not work in windows)
	   nc -vz localhost 2181 (this command may not work in windows) try in unix it will work surely.
	   Also we can check the status of the zookeeper using below command
	   zookeeper-shell.bat(windos) or ./zookeeper-shell.sh (linux)
	   
	   When zookeeper runs successfully you will see the following information
		
	    [2022-10-10 08:02:58,859] INFO Server environment:java.io.tmpdir=C:\Users\LENOVO\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,861] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,863] INFO Server environment:os.name=Windows 8.1 (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,879] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,881] INFO Server environment:os.version=6.3 (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,883] INFO Server environment:user.name=LENOVO (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,884] INFO Server environment:user.home=C:\Users\LENOVO (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,885] INFO Server environment:user.dir=I:\Kafka\kafka_2.13-2.6.0\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,886] INFO Server environment:os.memory.free=498MB (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,888] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,889] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,899] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,899] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:58,904] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir \tmp\zookeeper\version-2 snapdir \tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
		[2022-10-10 08:02:59,089] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
		[2022-10-10 08:02:59,154] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
		[2022-10-10 08:02:59,168] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
		[2022-10-10 08:02:59,231] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
		[2022-10-10 08:02:59,265] INFO Reading snapshot \tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
		[2022-10-10 08:02:59,295] INFO Snapshotting: 0x0 to \tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
		[2022-10-10 08:02:59,369] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)


	   
Step8: Now run the kafka broker, for this use the below command
       kafka-server-start.bat I:\Kafka\kafka_2.13-2.6.0\config\server.properties
	   default kafka server runs on 9092 port number
	   When kafka broker runs successfully we will the following  information below
	   
	   Output:
	   
		[2022-10-10 08:10:36,329] INFO [SocketServer brokerId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
		[2022-10-10 08:10:36,360] INFO Kafka version: 2.6.0 (org.apache.kafka.common.utils.AppInfoParser)
		[2022-10-10 08:10:36,367] INFO Kafka commitId: 62abe01bee039651 (org.apache.kafka.common.utils.AppInfoParser)
		[2022-10-10 08:10:36,368] INFO Kafka startTimeMs: 1665369636334 (org.apache.kafka.common.utils.AppInfoParser)
		[2022-10-10 08:10:36,379] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
      
Step9: Now create topic using below command
       kafka-topics.bat --bootstrap-server localhost:9092 --create --replication-factor 1 --partitions 3 --topic states
	   Output:
		Created topic states.
Step10: When successfully topic created,we will see following information in kafka server. with three partitions like below
        states-0 
		states-1 and 
		states-2

		[2022-10-10] INFO Creating topic states with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
		[2022-10-10] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(states-0, states-2, states-1) (kafka.server.ReplicaFetcherManager)
		[2022-10-10] INFO [Log partition=states-0, dir=I:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
		[2022-10-10] INFO Created log for partition states-0 in I:\tmp\kafka-logs\states-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.6-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
		[2022-10-10] INFO [Partition states-0 broker=0] No checkpointed highwatermark is found for partition states-0 (kafka.cluster.Partition)
		[2022-10-10] INFO [Partition states-0 broker=0] Log loaded for partition states-0 with initial high watermark 0 (kafka.cluster.Partition)
		[2022-10-10] INFO [Log partition=states-2, dir=I:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
		[2022-10-10] INFO Created log for partition states-2 in I:\tmp\kafka-logs\states-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.6-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
		[2022-10-10] INFO [Partition states-2 broker=0] No checkpointed highwatermark is found for partition states-2 (kafka.cluster.Partition)
		[2022-10-10] INFO [Partition states-2 broker=0] Log loaded for partition states-2 with initial high watermark 0 (kafka.cluster.Partition)
		[2022-10-10] INFO [Log partition=states-1, dir=I:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
		[2022-10-10] INFO Created log for partition states-1 in I:\tmp\kafka-logs\states-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.6-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
		[2022-10-10] INFO [Partition states-1 broker=0] No checkpointed highwatermark is found for partition states-1 (kafka.cluster.Partition)
		[2022-10-10] INFO [Partition states-1 broker=0] Log loaded for partition states-1 with initial high watermark 0 (kafka.cluster.Partition)
		  
Step11: We can come to know the list of topics created using below command
        kafka-topics.bat --bootstrap-server localhost:9092 --list
        Output: states
		
Step12: We can also know how many partitions creted and how many replication created and etc using followig command
		kafka-topics.bat --bootstrap-server localhost:9092 --describe --topic states
		Output: 
		Topic: states   PartitionCount: 3       ReplicationFactor: 1    Configs: segment.bytes=1073741824
        Topic: states   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: states   Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: states   Partition: 2    Leader: 0       Replicas: 0     Isr: 0

Step13: Now send messages to topic using kafka-console-producer.bat 
		I:\Kafka\kafka_2.13-2.6.0\bin\windows> kafka-console-producer.bat --bootstrap-server localhost:9092 --topic states
		and hit the enter button keyboard, then type messages and hit enter button it will go to partition in the topics (we created three partitions in topic)
		>This is the my first kafka message
		>This is the my second kafka message
		>Thsi is the my third kafka message
		>this is the my fourth kafka message
		>this is the my fifth kafka message
		
		Partition: Partition concept iplemented using rounrobit algoritham. so we can not handle messages to particular partition.
Step14: Now in another console run the kafka-console-consumer.bat (consumer serer) using following command 
		I:\Kafka\kafka_2.13-2.6.0\bin\windows>kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic states --from-beginning
        Output:
		This is the my second kafka message
		This is the my first kafka message
		Thsi is the my third kafka message
		this is the my fourth kafka message
		this is the my fifth kafka message
		
Step15: We also can read the messages from particular partition and particular offset and particular group
Step16: Read messages from group
        kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic states --group states
		(Note: It will not read the previous meessages, that means if you alread read the messages,it will read only new messages from group)
		kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic states  --from-beginning
		(It will read all the messages like old and new)
Step17: we can see list of group b issueing following command
        kafka-consumer-groups.bat --bootstrap-server localhost:9092 --list	
        Output: states
Step18: whether Kafka and zooker running backgroud or not to know status issue below command.
        \kafka\bin> nc -vz localhost 9092 for kafka
		\kafka\bin> nc -vz localhost 2181 for zookeeper
		

service zookeeper stop
service kafka stop


4lw.commands.whitelist=*
after placing the above whitelist command into each of the zookeeper.server file and when you run the zookeeper-server-start.sh file	
if we want to see whether zookeeper is running or not with user friendly then follow the below command
	echo "ruok" | nc localhost 2181	
	Output: amok
	echo "conf" | nc localhost 2181
	output: 
	       clientport=2181
		   dataDir = kafka log directory
		   dataDirSize = log file size 
		   etc
    echo "envi" | nc localhost 2181
	output: it shows lot of inormation about zookeeper like version, java version, etc
    echo "cons" | nc localhost 2181
	output: Queued(0), Received(0), Sent(0)
	echo "srvr" | nc localhost 2181  
	echo "stat" | nc localhost 2181
	
Now create three zookeeper servers and three kafka brokers(kafka servers)
=========================================================================
When ever we want to run the zookeeper in different server we can run using single zookeeper.properties without changing the port number.
But now we have only one machine so what we will do 
we will create three zookeeper.properties file using below
	zookeeper1.properties  client port number 2181           log file path dataDir=/tmp/zookeeper1(edit the zookeeper1.properties and change)
	zookeeper2.properties  client port number 2182            			   dataDir=/tmp/zookeeper2(edit the zookeeper2.properties and change)
	zookeeper3.properties  client port number 2183            			   dataDir=/tmp/zookeeper3(edit the zookeeper3.properties and change)
	
	(will change the log file path for each of zookeeper)

Now this is the time to create kafka brokers
	server1.properties     client port number 9092  log file path log.dirs=/tmp/kafka-logs1
	server2.properties     client port number 9093 log file path  log.dirs=/tmp/kafka-logs2
	server3.properties     client port number 9094  log file path log.dirs=/tmp/kafka-logs3
	
	once create the three brokers now opent he each of the server.properties file and change the below configuration.
	Step1: in server1.properties
	        broker.id=0 --> broker.id=101 (we can give any numer)
			listeners=PLAINTEXT://:9092  (uncommet this line)
			advertised.listeners=PLAINTEXT://your.host.name:9092 (uncomment this line and change give your host name)
			advertised.listeners=PLAINTEXT://localhost:9092
			log.dirs=/tmp/kafka-logs  -----> log.dirs=/tmp/kafka-logs1
			zookeeper.connect=localhost:2181, localhost:2182, localhost:2183
	Note: please update the remaining two server.properties file same as above and change the 
	                       broker.id=102, port number 9093 for server2.properties and ,
                       	   broker.id=103   and port number 9094 for server3.properties file and
          and also log file names 2 and 3 (just append in suffix of log direcory)	

Step1: After creating above 3 zookeeper and broker servers
Step2: Lets run those servers
Step3: run the following command on zookeeper path
       Zookeeper-shell.sh localhost:2181
       output: connnecting to 2181
	   next do the ls /brokers
	   output: [ids, seqid, topics]
	   nextagain do the ls /brokers/ids
	   output: [101, 102, 103]  //this broker ids we created in each of the server.properties file look at broker.id=101

Step4: you can very all the brokers are running or not.
      /bin> nc -vz localhost:9092
	  /bin> nc -vz localhost:9093
	  /bin> nc -vz localhost:9094

Step5: this is time to create topic
       bin> kafka-topics.sh --bootstrap-server localhost:9092, localhost:9093, localhost:9094 --create replication-factor 3 --partitions 5 --topic colors
	   Output: Created topic colors
	   
Step6: bin> kafka-topics.sh --bootstrap-server localhost:9092, localhost:9093, localhost:9094 --list
       output: colors

Step7: describe the broker using below command, we can get to know how many partitions are created and how many replicas created and topics ad Isr.
       bin> kafka-topics.sh --bootstrap-server localhost:9092, localhost:9093, localhost:9094	--describe
       outout: 
        Topic: colors Partition: 0 Leader : 102 Replicas: 102, 101, 103   ISR: 102, 101, 103
		Topic: colors Partition: 1 Leader : 101 Replicas: 101, 103, 102   ISR: 101, 103, 102
		Topic: colors Partition: 2 Leader : 103 Replicas: 103, 102, 101   ISR: 103, 102, 101
		Topic: colors Partition: 3 Leader : 102 Replicas: 102, 103, 101   ISR: 102, 101, 103
		Topic: colors Partition: 4 Leader : 101 Replicas: 101, 102, 103   ISR: 102, 103, 101
Step8: suppose broker 101 is down then it will create replica in 102 and 103 like that replicas [101, 103]	
        so no problem even one or two brokers are down , because another broker is running

Step9: now send message to topic colors 
      bin> kafka-console-producer.sh --bootstrap-server 	localhost:9092, localhost:9093, localhost:9094 --topic colors	
	     > Red
		 > Green
		 > Yellow>
		 > Pink
		 > White
		 > Blue
		 > press ctrl c , to come out
Step10: now we can see logs for which colors goes to which partition
         go to kafka[broker [in server.properties file we can find the path]] logs path 	then run the below command
         > ls -ltr	
		 Output:  below are the partitions
				 colors-0
				 colors-1
				 colors-3
		         colors-2
		         colors-4
		  We are not sure which messages goes to whihc partition when we send messages to topic colors 
		  We can also see which message goes to which partition
		  > cd coloros-0
		  > vi 00000000000000000.log
		  Yellow // this message stored to partition colors-0
		  like this we can check all the partiotions in all broker logs
step11: Now read messages from topic using below command
        bin> kafka-console-consumer.sh --bootstrap-server 	localhost:9092, localhost:9093, localhost:9094 --topic colors  --from-beginning
		   output: also read in randomly //bcz	round robin algoritham
		   Green
		   Yellow
		   White
		   Pink
		   Blue
		   Red

Step12: Read message from topic using group 	
        kafka-console-consumer.sh --bootstrap-server 	localhost:9092, localhost:9093, localhost:9094 --topic colors --group colors
		(Note: It will not read the previous meessages from topic, that means if you alread read the messages from the topic,
		it will read only new messages from group when you specify the group.)
		kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic states  --from-beginning
		(It will read all the messages include old and new) 

Step13: Now it's time to do performance testing
		Create new 
		
9010220449 y siva kumar reddy

Step13:    
		  
Wifi password : 7799744558